{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quora Insincere Questions Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manashpratim/Quora-Insincere-Questions-Classification/blob/master/Quora_Insincere_Questions_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i4x_29HjsHM",
        "colab_type": "code",
        "outputId": "f2ff2fde-cf66-4b99-c379-dbd1d38e51bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "#Downloading the Datasets\n",
        "!wget --no-check-certificate \\\n",
        "      \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/10737/290346/all.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1562496110&Signature=MoI4MS2ahHrnKTYhBs6GyCrawyQLaC6muis0M%2FcaHl54q1L6RnwVwc1ElWHX3UcZQToj1YhnmIg4Nm4veYgmbE%2BGU6qwWqlejyUCrRpIZCdrvO9QoCCW52zqjxWFJpJV2QuM7pj7C7gCAjqX9CzlP0OVWesj9tGD5GSRC9wQDfWPezEXUuI08LzWOt02rbexmuNZt7axZ%2B96EKGvBhBHCzndeC75CPNYRVjVs6evEoDUyzM7%2BTtA1R8JgwQgeBJtoEdxQ15OYFaU%2FOGMLePEPzf5XkcU8tI84BFzKLlc%2FDTewheg%2F0irr0xoMx6mCLJ%2BGt%2BszJFKVKgdB6zrKuxOLw%3D%3D&response-content-disposition=attachment%3B+filename%3Dquora-insincere-questions-classification.zip\"\\\n",
        "      -O \"/tmp/quora.zip\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-04 14:33:06--  https://storage.googleapis.com/kaggle-competitions-data/kaggle/10737/290346/all.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1562496110&Signature=MoI4MS2ahHrnKTYhBs6GyCrawyQLaC6muis0M%2FcaHl54q1L6RnwVwc1ElWHX3UcZQToj1YhnmIg4Nm4veYgmbE%2BGU6qwWqlejyUCrRpIZCdrvO9QoCCW52zqjxWFJpJV2QuM7pj7C7gCAjqX9CzlP0OVWesj9tGD5GSRC9wQDfWPezEXUuI08LzWOt02rbexmuNZt7axZ%2B96EKGvBhBHCzndeC75CPNYRVjVs6evEoDUyzM7%2BTtA1R8JgwQgeBJtoEdxQ15OYFaU%2FOGMLePEPzf5XkcU8tI84BFzKLlc%2FDTewheg%2F0irr0xoMx6mCLJ%2BGt%2BszJFKVKgdB6zrKuxOLw%3D%3D&response-content-disposition=attachment%3B+filename%3Dquora-insincere-questions-classification.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.70.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.70.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6475626955 (6.0G) [application/zip]\n",
            "Saving to: ‘/tmp/quora.zip’\n",
            "\n",
            "/tmp/quora.zip      100%[===================>]   6.03G   154MB/s    in 47s     \n",
            "\n",
            "2019-07-04 14:33:54 (131 MB/s) - ‘/tmp/quora.zip’ saved [6475626955/6475626955]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT8Kswg1lXNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzipping the downloaded dataset\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip='/tmp/quora.zip'\n",
        "zip_ref=zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp/quora')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf503KX6q2oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzipping the word embeddings\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip='/tmp/quora/embeddings.zip'\n",
        "zip_ref=zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp/quora/embeddings')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlrXcgANrhJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the Dataset\n",
        "import pandas as pd\n",
        "df=pd.read_csv('/tmp/quora/train.csv')\n",
        "df_test=pd.read_csv('/tmp/quora/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5f-fxoWs1kK",
        "colab_type": "code",
        "outputId": "aeb7dbb7-ee47-4f03-9aa1-f9c97ab188e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "df.head(3)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... target\n",
              "0  00002165364db923c7e6  ...      0\n",
              "1  000032939017120e6e44  ...      0\n",
              "2  0000412ca6e4628ce2cf  ...      0\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d7TbgQvZ47S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "4d29ce7c-d250-46cb-801c-837415c6d886"
      },
      "source": [
        "df_test.head(3)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>Why do so many women become so rude and arroga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>When should I apply for RV college of engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>What is it really like to be a nurse practitio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid                                      question_text\n",
              "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
              "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
              "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-duWAgEwtd7v",
        "colab_type": "code",
        "outputId": "8a1d881f-f092-44ab-b431-75fa062874ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#Class Distribution\n",
        "df['target'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1225312\n",
              "1      80810\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-bdNTbdtLhY",
        "colab_type": "code",
        "outputId": "3950452b-fbcc-498d-822d-79858c8490fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#Functions for Preprocessing the Dataset\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def mystopwords(text):\n",
        "    return ' '.join([w for w in word_tokenize(text) if not w in stop_words])\n",
        "\n",
        "import re\n",
        "def clean_text(string):\n",
        "  clean=re.sub('[\\n]',' ',string) #remove newline character\n",
        "  clean=re.sub('[^a-zA-Z]',' ',clean) #remove non alphabetic characters\n",
        "  clean=mystopwords(clean) #remove stopwords\n",
        "  return clean"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BWdGI8QtTlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning the data and separating the texts and labels\n",
        "sentences=[]\n",
        "labels=[]\n",
        "for i in range(len(df)):\n",
        "  labels.append(df['target'][i])\n",
        "  sentences.append(clean_text(df['question_text'][i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnx8KTnednfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentences=[]\n",
        "for i in range(len(df_test)):\n",
        "  test_sentences.append(clean_text(df['question_text'][i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLMGL77muVlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Suffling the data and splitting the data into train and test sets (90:10)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_sentences, val_sentences, train_labels, val_labels= train_test_split(sentences, labels, test_size=0.1, shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB1h2-DVu0TN",
        "colab_type": "code",
        "outputId": "e5037522-40cc-4a88-95c2-430774d00b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#Data Summary\n",
        "print('Length of the Data: ',len(df))\n",
        "print('No. of Training Examples: ',len(train_sentences))\n",
        "print('No. of Validation Examples: ',len(val_sentences))\n",
        "print('No. of Classes: ',df['target'].nunique())"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the Data:  1306122\n",
            "No. of Training Examples:  1175509\n",
            "No. of Validation Examples:  130613\n",
            "No. of Classes:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDyEl0KDPsTL",
        "colab_type": "text"
      },
      "source": [
        "## **Multinomial Naive Bayes Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyuvIfWDvye8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "pipeline=Pipeline([('bow',CountVectorizer(analyzer=clean_text)),\n",
        "                   ('tfidf',TfidfTransformer()),\n",
        "                   ('classifier',MultinomialNB())\n",
        "                   ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLYm-R4dP43R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "d59e14e8-239d-472c-87a5-00215259d4f6"
      },
      "source": [
        "pipeline.fit(train_sentences,train_labels)\n",
        "pred=pipeline.predict(val_sentences)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Test Accuracy using MultiNomial Naive Bayes Classifier: ',accuracy_score(val_labels,pred))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_labels,pred))\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "CM = confusion_matrix(val_labels, pred)\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy using MultiNomial Naive Bayes Classifier:  0.9377703597651076\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97    122485\n",
            "           1       0.00      0.00      0.00      8128\n",
            "\n",
            "    accuracy                           0.94    130613\n",
            "   macro avg       0.47      0.50      0.48    130613\n",
            "weighted avg       0.88      0.94      0.91    130613\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAFACAYAAADOJ6uCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A87pt-lU-lq",
        "colab_type": "text"
      },
      "source": [
        "### **While the classifier has a high accuracy, it fails to classify  even a single example from the minority class **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pwexz7XSo0J",
        "colab_type": "text"
      },
      "source": [
        "## **Support Vector Machines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO0bOiSHQJIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "pipeline=Pipeline([('bow',CountVectorizer(analyzer=clean_text)),\n",
        "                   ('tfidf',TfidfTransformer()),\n",
        "                   ('classifier',SVC())\n",
        "                   ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVPkPqi2SzLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "9aeff826-9706-4ec7-a3ac-0650a1dbd8d9"
      },
      "source": [
        "pipeline.fit(train_sentences,train_labels)\n",
        "pred=pipeline.predict(val_sentences)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Test Accuracy using Support Vector Machines: ',accuracy_score(val_labels,pred))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_labels,pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "CM = confusion_matrix(val_labels, pred)\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38d7tgwpUdf7",
        "colab_type": "text"
      },
      "source": [
        "## **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0S-nppyUmVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "pipeline=Pipeline([('bow',CountVectorizer(analyzer=clean_text)),\n",
        "                   ('tfidf',TfidfTransformer()),\n",
        "                   ('classifier',LogisticRegression())\n",
        "                   ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L5z57cOU3xP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "97704bf1-d8ba-447d-e93c-2fd96668a585"
      },
      "source": [
        "pipeline.fit(train_sentences,train_labels)\n",
        "pred=pipeline.predict(val_sentences)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Test Accuracy using Logistic Regression Classifier: ',accuracy_score(val_labels,pred))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_labels,pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "CM = confusion_matrix(val_labels, pred)\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy using Logistic Regression Classifier:  0.9377320787364198\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97    122485\n",
            "           1       0.44      0.00      0.00      8128\n",
            "\n",
            "    accuracy                           0.94    130613\n",
            "   macro avg       0.69      0.50      0.49    130613\n",
            "weighted avg       0.91      0.94      0.91    130613\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAFACAYAAADOJ6uCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U67gW_paVj6V",
        "colab_type": "text"
      },
      "source": [
        "## **Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtbB5uIKVjAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "pipeline=Pipeline([('bow',CountVectorizer(analyzer=clean_text)),\n",
        "                   ('tfidf',TfidfTransformer()),\n",
        "                   ('classifier',RandomForestClassifier(n_estimators=200))\n",
        "                   ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOGyD6N_WRxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "1813b260-4cce-48e3-a56c-a3d7ec51707e"
      },
      "source": [
        "pipeline.fit(train_sentences,train_labels)\n",
        "pred=pipeline.predict(val_sentences)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Test Accuracy using Random Forest Classifier: ',accuracy_score(val_labels,pred))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_labels,pred))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "CM = confusion_matrix(val_labels, pred)\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-66ad07369f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Accuracy using Random Forest Classifier: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF3O5yRaYWsJ",
        "colab_type": "text"
      },
      "source": [
        "# **Word Embedding Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_tJ81sOYeqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a114bc06-c616-405e-d07d-3dcc7b2241b5"
      },
      "source": [
        "#Tokenization and Padding\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "embedding_dim = 300\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "vocab_len=49999\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_len+1,oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index)\n",
        "print('Original Size of Vocabulary: ',vocab_size)\n",
        "\n",
        "word_index = {e:i for e,i in word_index.items() if i <= vocab_len+1} #Reducing the Size of Vocabulary\n",
        "print('New Size of Vocabulary: ',len(word_index))\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "train_labels=np.expand_dims(train_labels, axis=1)\n",
        "val_labels=np.expand_dims(val_labels, axis=1)\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Size of Vocabulary:  178863\n",
            "New Size of Vocabulary:  50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYpxyjtjhEzh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "2e0a3fe8-8531-4206-830e-1b1efd0634cd"
      },
      "source": [
        "#Dimension of Data after Tokenizing and Padding\n",
        "print('Dimension of Training Data: ',train_padded.shape)\n",
        "print('Dimension of Validation Data: ',val_padded.shape)\n",
        "print('Dimension of Training Labels: ',train_labels.shape)\n",
        "print('Dimension of Validation Labels: ',val_labels.shape)\n",
        "print('Dimension of Test Data: ',test_padded.shape)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension of Training Data:  (1175509, 100)\n",
            "Dimension of Validation Data:  (130613, 100)\n",
            "Dimension of Training Labels:  (1175509, 1)\n",
            "Dimension of Validation Labels:  (130613, 1)\n",
            "Dimension of Test Data:  (375806, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBpItmz724Fq",
        "colab_type": "text"
      },
      "source": [
        "## **Bidirectional LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEeuA_LKiJYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ff18eada-63aa-41a3-bdd8-f3a285295789"
      },
      "source": [
        "#Building the Bidirectional LSTM Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_len+1, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0704 15:41:22.348512 139660615804800 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0704 15:41:22.351063 139660615804800 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0704 15:41:22.352190 139660615804800 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jVsNlOKiUxU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "0e4f1907-440f-46de-f71b-9de28e69ddb8"
      },
      "source": [
        "reduce =tf. keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto')\n",
        "#early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, mode='auto')\n",
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "num_epochs = 5\n",
        "history=model.fit(train_padded, train_labels, epochs=num_epochs, batch_size=1024, validation_data=(val_padded,val_labels),callbacks=[reduce],verbose=1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/5\n",
            "1175509/1175509 [==============================] - 444s 378us/sample - loss: 0.1237 - acc: 0.9521 - val_loss: 0.1170 - val_acc: 0.9533\n",
            "Epoch 2/5\n",
            "1175509/1175509 [==============================] - 438s 372us/sample - loss: 0.1123 - acc: 0.9562 - val_loss: 0.1164 - val_acc: 0.9536\n",
            "Epoch 3/5\n",
            "1175509/1175509 [==============================] - 437s 372us/sample - loss: 0.1070 - acc: 0.9586 - val_loss: 0.1139 - val_acc: 0.9556\n",
            "Epoch 4/5\n",
            "1175509/1175509 [==============================] - 436s 371us/sample - loss: 0.1031 - acc: 0.9604 - val_loss: 0.1138 - val_acc: 0.9556\n",
            "Epoch 5/5\n",
            "1175509/1175509 [==============================] - 436s 370us/sample - loss: 0.0987 - acc: 0.9624 - val_loss: 0.1159 - val_acc: 0.9543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1G6_oKKlaaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "53cdb2cc-add5-40a9-e6a3-237255fbb575"
      },
      "source": [
        "#Determining the optimal threshold value to seggregate the classes\n",
        "pred_noemb_val_labels = model.predict(val_padded, batch_size=1024,verbose=1)\n",
        "from sklearn import metrics\n",
        "for thresh in np.arange(0.1, 0.5, 0.05):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_labels, (pred_noemb_val_labels>thresh).astype(int))))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "130613/130613 [==============================] - 18s 137us/sample\n",
            "F1 score at threshold 0.1 is 0.550374985119638\n",
            "F1 score at threshold 0.15 is 0.5847472605160834\n",
            "F1 score at threshold 0.2 is 0.6066278292426703\n",
            "F1 score at threshold 0.25 is 0.6199002950452742\n",
            "F1 score at threshold 0.3 is 0.6273268601469877\n",
            "F1 score at threshold 0.35 is 0.6323736548537945\n",
            "F1 score at threshold 0.4 is 0.6317893251822243\n",
            "F1 score at threshold 0.45 is 0.6265192695291029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyNBkAX3kWCx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "4ed02129-2dc3-4305-ca9f-83b275d18c53"
      },
      "source": [
        "# From above, we can see that F1 score is highest at a threshold of 0.35\n",
        "pred_val_labels=(pred_noemb_val_labels>0.35).astype(int)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_labels,pred_val_labels))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(val_labels, pred_val_labels))\n",
        "CM = confusion_matrix(val_labels, pred_val_labels)\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97    122485\n",
            "           1       0.58      0.69      0.63      8128\n",
            "\n",
            "    accuracy                           0.95    130613\n",
            "   macro avg       0.78      0.83      0.80    130613\n",
            "weighted avg       0.95      0.95      0.95    130613\n",
            "\n",
            "[[118476   4009]\n",
            " [  2516   5612]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAFACAYAAADOJ6uCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbDYQOgo3aog",
        "colab_type": "text"
      },
      "source": [
        "# **Pretrained Word Embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-KlJRAc35zm",
        "colab_type": "text"
      },
      "source": [
        "## **fastText**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIFv_7dlzKgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the pretrained vectors\n",
        "embeddings_index = {}\n",
        "import numpy as np\n",
        "with open('/tmp/quora/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec') as f:\n",
        "    for line in f:\n",
        "      try:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "      except:\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_KTEKwe4DJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating an embedding matrix that contains the vectors of the words in the dataset\n",
        "embeddings_matrix = np.zeros((vocab_len+2, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embeddings_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvfyb_uWIdSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_matrix=np.delete(embeddings_matrix, 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD7Guec6H5xc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2121124a-8e3e-4150-90f1-fe7336c2a7c5"
      },
      "source": [
        "print('Shape of Embedding Matrix: ',embeddings_matrix.shape)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Embedding Matrix:  (50000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRPMjWg9I7W0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_len+1, embedding_dim, input_length=max_length, weights = [embeddings_matrix], trainable = False),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwMcAirtJLTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "aad71833-34da-4ddc-d51e-489d6528f1d6"
      },
      "source": [
        "reduce =tf. keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, mode='auto')\n",
        "#early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, mode='auto')\n",
        "model2.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
        "num_epochs = 5\n",
        "history2=model2.fit(train_padded, \n",
        "                    train_labels, \n",
        "                    epochs=num_epochs, \n",
        "                    batch_size=1024, \n",
        "                    validation_data=(val_padded,val_labels),\n",
        "                    callbacks=[reduce],\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/5\n",
            "1174528/1175509 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9406"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlPU0HspM34S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Determining the optimal threshold value to seggregate the classes\n",
        "pred_ft_val_labels = model2.predict(val_padded, batch_size=1024,verbose=1)\n",
        "from sklearn import metrics\n",
        "for thresh in np.arange(0.1, 0.5, 0.05):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_labels, (pred_ft_val_labels>thresh).astype(int))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkbdsyMJNB8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From above, we can see that F1 score is highest at a threshold of 0.35\n",
        "pred_ft_val_labels=(pred_ft_val_labels>0.35).astype(int)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(val_labels,pred_ft_val_labels))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(val_labels, pred_ft_val_labels))\n",
        "CM = confusion_matrix(val_labels, pred_ft_val_labels)\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}